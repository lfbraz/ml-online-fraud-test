{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"spambase.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9  ...    48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
       "\n",
       "    50     51     52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = spam.loc[:,0:56]\n",
    "y = spam.loc[:,57]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3220, 57)\n",
      "(1381, 57)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = mlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99870530e-01,   1.29469668e-04],\n",
       "       [  7.33596485e-04,   9.99266404e-01],\n",
       "       [  9.82620106e-01,   1.73798942e-02],\n",
       "       ..., \n",
       "       [  1.00000000e+00,   1.43884135e-10],\n",
       "       [  8.37001585e-01,   1.62998415e-01],\n",
       "       [  9.99999956e-01,   4.36059147e-08]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.9457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"acurácia: %.4f\" % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[787  29]\n",
      " [ 46 519]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95       816\n",
      "          1       0.95      0.92      0.93       565\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print classification_report(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'hidden_layer_sizes': [(1,), (5,), (10,), (5,5,)],\n",
    "                     'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                     'learning_rate': ['constant', 'adaptive'],\n",
    "                     'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlos/Documents/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'learning_rate': ['constant', 'adaptive'], 'hidden_layer_sizes': [(1,), (5,), (10,), (5, 5)]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(MLPClassifier(), tuned_parameters, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.920 (+/-0.004) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.919 (+/-0.004) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.922 (+/-0.007) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.922 (+/-0.005) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.921 (+/-0.005) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.921 (+/-0.006) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.921 (+/-0.007) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.922 (+/-0.004) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.916 (+/-0.011) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.919 (+/-0.005) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.921 (+/-0.004) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.920 (+/-0.005) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.922 (+/-0.006) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.922 (+/-0.005) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.922 (+/-0.005) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.920 (+/-0.006) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.920 (+/-0.008) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.917 (+/-0.009) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.921 (+/-0.006) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.921 (+/-0.004) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.922 (+/-0.004) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.922 (+/-0.004) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.922 (+/-0.006) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.921 (+/-0.003) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.917 (+/-0.011) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.919 (+/-0.008) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.922 (+/-0.008) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.922 (+/-0.004) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.923 (+/-0.004) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.921 (+/-0.005) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.922 (+/-0.003) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.922 (+/-0.005) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.918 (+/-0.001) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.916 (+/-0.003) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.919 (+/-0.003) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.919 (+/-0.005) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.920 (+/-0.006) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.920 (+/-0.004) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.921 (+/-0.006) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.922 (+/-0.004) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.920 (+/-0.009) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.921 (+/-0.008) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.926 (+/-0.009) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.925 (+/-0.007) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.925 (+/-0.005) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.928 (+/-0.012) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.925 (+/-0.009) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.927 (+/-0.007) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.921 (+/-0.001) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.920 (+/-0.006) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.925 (+/-0.006) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.925 (+/-0.004) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.927 (+/-0.006) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.928 (+/-0.009) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.927 (+/-0.007) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.927 (+/-0.008) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.922 (+/-0.008) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.919 (+/-0.007) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.925 (+/-0.006) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.925 (+/-0.007) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.927 (+/-0.005) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.926 (+/-0.007) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.927 (+/-0.008) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.928 (+/-0.006) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.917 (+/-0.002) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.919 (+/-0.003) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.927 (+/-0.004) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.925 (+/-0.000) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.929 (+/-0.005) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.929 (+/-0.007) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.925 (+/-0.003) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.926 (+/-0.006) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.914 (+/-0.005) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.913 (+/-0.009) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.924 (+/-0.005) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.923 (+/-0.005) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.921 (+/-0.006) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.922 (+/-0.005) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.920 (+/-0.006) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.924 (+/-0.005) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.924 (+/-0.007) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.924 (+/-0.008) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.930 (+/-0.006) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.930 (+/-0.006) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.933 (+/-0.004) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.928 (+/-0.008) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.926 (+/-0.009) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.933 (+/-0.009) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.924 (+/-0.006) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.926 (+/-0.011) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.927 (+/-0.007) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.928 (+/-0.003) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.932 (+/-0.002) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.931 (+/-0.005) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.928 (+/-0.012) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.929 (+/-0.007) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.923 (+/-0.010) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.926 (+/-0.006) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.930 (+/-0.006) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.928 (+/-0.006) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.935 (+/-0.011) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.932 (+/-0.008) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.932 (+/-0.002) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.930 (+/-0.003) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.924 (+/-0.002) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.923 (+/-0.012) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.928 (+/-0.005) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.931 (+/-0.006) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.933 (+/-0.005) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.929 (+/-0.005) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.929 (+/-0.010) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.930 (+/-0.002) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.923 (+/-0.009) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.921 (+/-0.009) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.929 (+/-0.002) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.932 (+/-0.003) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.929 (+/-0.006) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.930 (+/-0.001) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.933 (+/-0.012) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.933 (+/-0.004) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.921 (+/-0.013) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.920 (+/-0.005) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.931 (+/-0.011) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.929 (+/-0.011) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.929 (+/-0.003) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.929 (+/-0.006) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.932 (+/-0.011) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.924 (+/-0.004) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.921 (+/-0.008) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.916 (+/-0.009) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.930 (+/-0.005) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.928 (+/-0.003) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.931 (+/-0.008) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.935 (+/-0.011) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.927 (+/-0.008) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.931 (+/-0.003) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.920 (+/-0.008) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.921 (+/-0.014) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.930 (+/-0.001) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.930 (+/-0.005) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.931 (+/-0.001) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.933 (+/-0.004) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.929 (+/-0.015) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.935 (+/-0.007) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.914 (+/-0.008) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.915 (+/-0.013) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.930 (+/-0.012) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.928 (+/-0.012) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.933 (+/-0.004) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.935 (+/-0.011) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.928 (+/-0.003) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.932 (+/-0.013) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.919 (+/-0.009) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.918 (+/-0.005) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.931 (+/-0.007) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.931 (+/-0.002) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.933 (+/-0.005) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.931 (+/-0.005) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.930 (+/-0.003) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.928 (+/-0.006) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95       816\n",
      "          1       0.93      0.92      0.93       565\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1381\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95       842\n",
      "          1       0.95      0.89      0.92       539\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 500, 'max_depth': 2, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01}\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977016027746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test,clf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'n_estimators': [10, 100, 300],\n",
    "                     'max_depth' : [3, 10],\n",
    "                     'min_samples_split': [2, 10],\n",
    "                     'learning_rate': [0.001, 0.1], \n",
    "                     'subsample': [0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 100, 300], 'max_depth': [3, 10], 'min_samples_split': [2, 10], 'learning_rate': [0.001, 0.1], 'subsample': [0.5, 1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(ensemble.GradientBoostingClassifier(), tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.612 (+/-0.001) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.837 (+/-0.019) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.839 (+/-0.024) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.837 (+/-0.023) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.839 (+/-0.024) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.902 (+/-0.009) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.902 (+/-0.011) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.612 (+/-0.001) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.902 (+/-0.011) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.903 (+/-0.015) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.910 (+/-0.017) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.911 (+/-0.014) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.940 (+/-0.008) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.943 (+/-0.014) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.944 (+/-0.011) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.948 (+/-0.012) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.914 (+/-0.012) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.911 (+/-0.014) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.939 (+/-0.012) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.942 (+/-0.013) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.941 (+/-0.008) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.948 (+/-0.009) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.923 (+/-0.016) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.910 (+/-0.011) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.946 (+/-0.006) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.945 (+/-0.009) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.947 (+/-0.010) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.943 (+/-0.016) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.925 (+/-0.012) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.919 (+/-0.007) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.947 (+/-0.010) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.946 (+/-0.010) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.942 (+/-0.010) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.946 (+/-0.007) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.96       816\n",
      "          1       0.95      0.94      0.95       565\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1381\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95       816\n",
      "          1       0.94      0.90      0.92       565\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf', 'linear', 'poly'],\n",
    "                     'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kernel': ['rbf', 'linear', 'poly'], 'C': [1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'kernel': 'rbf', 'C': 1}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.927 (+/-0.015) for {'kernel': 'rbf', 'C': 1}\n",
      "0.922 (+/-0.007) for {'kernel': 'linear', 'C': 1}\n",
      "0.759 (+/-0.013) for {'kernel': 'poly', 'C': 1}\n",
      "0.927 (+/-0.012) for {'kernel': 'rbf', 'C': 10}\n",
      "0.923 (+/-0.006) for {'kernel': 'linear', 'C': 10}\n",
      "0.845 (+/-0.010) for {'kernel': 'poly', 'C': 10}\n",
      "0.914 (+/-0.006) for {'kernel': 'rbf', 'C': 100}\n",
      "0.923 (+/-0.007) for {'kernel': 'linear', 'C': 100}\n",
      "0.913 (+/-0.013) for {'kernel': 'poly', 'C': 100}\n",
      "0.907 (+/-0.014) for {'kernel': 'rbf', 'C': 1000}\n",
      "0.924 (+/-0.006) for {'kernel': 'linear', 'C': 1000}\n",
      "0.915 (+/-0.031) for {'kernel': 'poly', 'C': 1000}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95       816\n",
      "          1       0.94      0.90      0.92       565\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1381\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
